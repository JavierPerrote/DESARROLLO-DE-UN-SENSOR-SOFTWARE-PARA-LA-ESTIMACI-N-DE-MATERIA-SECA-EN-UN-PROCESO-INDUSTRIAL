{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JavierPerrote/DESARROLLO-DE-UN-SENSOR-SOFTWARE-PARA-LA-ESTIMACION-DE-MATERIA-SECA-EN-UN-PROCESO-INDUSTRIAL/blob/main/Modelado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26v0aly3g3mi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import math as math\n",
        "import scipy.signal\n",
        "import re\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiplB6-Hg41z"
      },
      "outputs": [],
      "source": [
        "dataFile = pd.read_csv('sensor.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDsUAEJCg7M5"
      },
      "outputs": [],
      "source": [
        "#transformo las Presiones de los ultimos dos efectos a presiones relativas\n",
        "dataFile[\"P_vah_e5\"] = dataFile[\"P_vah_e5\"] - 1.013251\n",
        "dataFile[\"P_vah_e6\"] = dataFile[\"P_vah_e6\"] - 1.013251"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCNBVFvZg9q4"
      },
      "outputs": [],
      "source": [
        "# Primero generamos el filtro\n",
        "dataFiltered = dataFile.copy()\n",
        "for index,column in enumerate(dataFile.columns):\n",
        "\n",
        "\n",
        "    if (column == 'Output'):\n",
        "        b, a = scipy.signal.butter(2, 0.007)\n",
        "        dataFiltered[column] = scipy.signal.filtfilt(b, a, dataFile[column], axis=0,padlen=100 )\n",
        "\n",
        "\n",
        "    if re.match(r'^[pP]_va[hp]', column):\n",
        "        b, a = scipy.signal.butter(2, 0.003)\n",
        "        dataFiltered[column] = scipy.signal.filtfilt(b, a, dataFile[column], axis=0,padlen=100 )\n",
        "\n",
        "\n",
        "    if (column.startswith('T_')):\n",
        "        b, a = scipy.signal.butter(2, 0.005)\n",
        "        dataFiltered[column] = scipy.signal.filtfilt(b, a, dataFile[column], axis=0,padlen=100 )\n",
        "\n",
        "\n",
        "    if re.match(r'^e._T', column):\n",
        "        b, a = scipy.signal.butter(2, 0.005)\n",
        "        dataFiltered[column] = scipy.signal.filtfilt(b, a, dataFile[column], axis=0,padlen=100 )\n",
        "\n",
        "    if (column.startswith('W_')):\n",
        "        b, a = scipy.signal.butter(2, 0.005)\n",
        "        dataFiltered[column] = scipy.signal.filtfilt(b, a, dataFile[column], axis=0,padlen=100 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeKIvYmig_4H"
      },
      "outputs": [],
      "source": [
        "#eliminamos variables repetidas\n",
        "dataFiltered.drop(['W_jugo_R4', 'W_jugo_R8', 'W_jugo_R9', 'W_jugo_anteevap'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjHqQqt6hDC6"
      },
      "outputs": [],
      "source": [
        "# separamos los atributos de la clase\n",
        "X = dataFiltered.drop(columns = [\"Output\"])\n",
        "y = dataFiltered[\"Output\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lD6cHghCh_kx"
      },
      "outputs": [],
      "source": [
        "#ENTRENAMIENTO - TEST\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whUNMxChjMnz"
      },
      "outputs": [],
      "source": [
        "#NORMALIZACIÓN + PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Normalizar características del conjunto de entrenamiento\n",
        "scaler_train = MinMaxScaler()\n",
        "X_train_norm = scaler_train.fit_transform(X_train)\n",
        "\n",
        "# Normalizar características del conjunto de prueba\n",
        "X_test_norm = scaler_train.transform(X_test)\n",
        "\n",
        "# Normalizar la variable respuesta del conjunto de entrenamiento\n",
        "y_scaler_train = MinMaxScaler()\n",
        "y_train_norm = y_scaler_train.fit_transform(y_train.values.reshape(-1, 1))\n",
        "\n",
        "# Normalizar la variable respuesta del conjunto de prueba\n",
        "y_test_norm = y_scaler_train.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Realizar ACP en el conjunto de entrenamiento\n",
        "pca_train = PCA(n_components=10)\n",
        "X_train_pca = pca_train.fit_transform(X_train_norm)\n",
        "\n",
        "# Proyectar el conjunto de prueba en el espacio de los componentes principales\n",
        "X_test_pca = pca_train.transform(X_test_norm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3L5jS8-iC-P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "# Definir modelo para búsqueda de hiperparámetros\n",
        "\n",
        "def create_model(num_layers, num_neurons, learning_rate):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Input(shape=X_train_pca.shape[1]))\n",
        "\n",
        "    # Capas ocultas\n",
        "    for i in range(num_layers):\n",
        "        model.add(layers.Dense(units=num_neurons, activation='relu'))\n",
        "\n",
        "    # Capa de salida\n",
        "    model.add(layers.Dense(units=1, activation='linear'))\n",
        "\n",
        "    # Compilación del modelo\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss='mean_squared_error',\n",
        "        metrics=['mse']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Construimos el estimador Keras para poder disfrutar de las ventajas de Scikit-Learn\n",
        "Keras = KerasRegressor(build_fn=create_model, verbose=0)\n",
        "\n",
        "# Definimos los hiperparámetros y sus posibles valores\n",
        "param_distribs = {\n",
        "    'num_layers': [1,2,3],\n",
        "    'num_neurons': [5,10,15,20],\n",
        "    'learning_rate': [0.001, 0.01, 0.1]\n",
        "}\n",
        "\n",
        "# Búsqueda aleatoria con validación cruzada\n",
        "rnd_search_cv = GridSearchCV(Keras, param_grid=param_distribs,\n",
        "                             scoring='neg_mean_squared_error')\n",
        "\n",
        "rnd_search_cv.fit(X_train_pca, y_train_norm, epochs=10)\n",
        "# Obtenemos el mejor modelo\n",
        "best_model = rnd_search_cv.best_estimator_.model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJTe8GWx5ZqT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Mostramos los hiperparámetros del mejor modelo\n",
        "print(\"Hiperparámetros del mejor modelo:\")\n",
        "print(rnd_search_cv.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdxiYCPmhLES"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Entrenar el modelo con todos los datos de entrenamiento\n",
        "best_model.fit(X_train_pca, y_train_norm,epochs=10)\n",
        "\n",
        "# Realizar predicciones con el modelo\n",
        "y_pred_train = best_model.predict(X_train_pca)\n",
        "y_pred_test = best_model.predict(X_test_pca)\n",
        "\n",
        "# Calcular el error cuadrático medio para los datos de entrenamiento y prueba\n",
        "mse_train = mean_squared_error(y_train_norm, y_pred_train)\n",
        "mse_test = mean_squared_error(y_test_norm, y_pred_test)\n",
        "\n",
        "print(\"MSE en datos de entrenamiento: \", mse_train)\n",
        "print(\"MSE en datos de prueba: \", mse_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgcvknn_hM61"
      },
      "outputs": [],
      "source": [
        "y_pred_train_desnormalizado = y_scaler_train.inverse_transform(y_pred_train.reshape(-1,1))\n",
        "y_pred_test_desnormalizado = y_scaler_train.inverse_transform(y_pred_test.reshape(-1,1))\n",
        "\n",
        "mse_train_desnormalizado = mean_squared_error(y_train, y_pred_train_desnormalizado)\n",
        "mse_test_desnormalizado = mean_squared_error(y_test, y_pred_test_desnormalizado)\n",
        "\n",
        "print(\"MSE en datos de entrenamiento desnormalizado: \", mse_train_desnormalizado)\n",
        "print(\"MSE en datos de prueba desnormalizado: \", mse_test_desnormalizado)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abe7Q3BBisfb"
      },
      "outputs": [],
      "source": [
        "x=np.arange(0,len(dataFile['Output']))\n",
        "#Output\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "actual = np.append(y_train, y_test)\n",
        "predictions = np.append(y_pred_train_desnormalizado, y_pred_test_desnormalizado)\n",
        "plt.figure()\n",
        "plt.plot(x, dataFile['Output'] , label='real')\n",
        "plt.plot(x,predictions, label='prediccion')\n",
        "plt.axvline(x=len(y_train), color='red', linestyle='--')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV4saMlPAsPf"
      },
      "outputs": [],
      "source": [
        "x=np.arange(len(y_train),len(dataFile['Output']))\n",
        "#Output\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "plt.figure()\n",
        "plt.plot(x, dataFile['Output'][len(y_train):] , label='real')\n",
        "plt.plot(x,y_pred_test_desnormalizado, label='prediccion')\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYugZaBhaz31"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "# Definir modelo para búsqueda de hiperparámetros\n",
        "\n",
        "def create_model(num_layers,num_neurons, learning_rate):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Input(shape=X_train_pca.shape[1]))\n",
        "\n",
        "    # Capas ocultas\n",
        "    for i in range(2):\n",
        "        model.add(layers.Dense(units=num_neurons, activation='relu'))\n",
        "\n",
        "    # Capa de salida\n",
        "    model.add(layers.Dense(units=1, activation='linear'))\n",
        "\n",
        "    # Compilación del modelo\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss='mean_squared_error',\n",
        "        metrics=['mse']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Construimos el estimador Keras para poder disfrutar de las ventajas de Scikit-Learn\n",
        "Keras = KerasRegressor(build_fn=create_model, verbose=0)\n",
        "\n",
        "# Definimos los hiperparámetros y sus posibles valores\n",
        "param_distribs = {\n",
        "    'num_layers': [1,2],\n",
        "    'num_neurons': [5,10,15],\n",
        "    'learning_rate': [0.001, 0.01,0.1]\n",
        "}\n",
        "\n",
        "# Búsqueda aleatoria con validación cruzada\n",
        "rnd_search_cv = GridSearchCV(Keras, param_grid=param_distribs,\n",
        "                             scoring='neg_mean_squared_error')\n",
        "#rnd_search_cv.fit(X_train_pca, y_train_norm)\n",
        "rnd_search_cv.fit(X_train_pca, y_train_norm, epochs=10)\n",
        "# Obtenemos el mejor modelo\n",
        "best_model = rnd_search_cv.best_estimator_.model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktlZjw1Sftde"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Mostramos los hiperparámetros del mejor modelo\n",
        "print(\"Hiperparámetros del mejor modelo:\")\n",
        "print(rnd_search_cv.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9YzvZjdfvbd"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Entrenar el modelo con todos los datos de entrenamiento\n",
        "best_model.fit(X_train_pca, y_train_norm,epochs=10)\n",
        "\n",
        "# Realizar predicciones con el modelo\n",
        "y_pred_train = best_model.predict(X_train_pca)\n",
        "y_pred_test = best_model.predict(X_test_pca)\n",
        "\n",
        "# Calcular el error cuadrático medio para los datos de entrenamiento y prueba\n",
        "mse_train = mean_squared_error(y_train_norm, y_pred_train)\n",
        "mse_test = mean_squared_error(y_test_norm, y_pred_test)\n",
        "\n",
        "print(\"MSE en datos de entrenamiento: \", mse_train)\n",
        "print(\"MSE en datos de prueba: \", mse_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMpoiKO1f3Zp"
      },
      "outputs": [],
      "source": [
        "y_pred_train_desnormalizado = y_scaler_train.inverse_transform(y_pred_train.reshape(-1,1))\n",
        "y_pred_test_desnormalizado = y_scaler_train.inverse_transform(y_pred_test.reshape(-1,1))\n",
        "\n",
        "mse_train_desnormalizado = mean_squared_error(y_train, y_pred_train_desnormalizado)\n",
        "mse_test_desnormalizado = mean_squared_error(y_test, y_pred_test_desnormalizado)\n",
        "\n",
        "print(\"MSE en datos de entrenamiento desnormalizado: \", mse_train_desnormalizado)\n",
        "print(\"MSE en datos de prueba desnormalizado: \", mse_test_desnormalizado)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0DsMd4af5eh"
      },
      "outputs": [],
      "source": [
        "x=np.arange(0,len(dataFile['Output']))\n",
        "#Output\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "actual = np.append(y_train, y_test)\n",
        "predictions = np.append(y_pred_train_desnormalizado, y_pred_test_desnormalizado)\n",
        "plt.figure()\n",
        "plt.plot(x, dataFile['Output'] , label='real')\n",
        "plt.plot(x,predictions, label='prediccion')\n",
        "plt.axvline(x=len(y_train), color='red', linestyle='--')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krqxX--Xf6J7"
      },
      "outputs": [],
      "source": [
        "x=np.arange(len(y_train),len(dataFile['Output']))\n",
        "#Output\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "plt.figure()\n",
        "plt.plot(x, dataFile['Output'][len(y_train):] , label='real')\n",
        "plt.plot(x,y_pred_test_desnormalizado, label='prediccion')\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNAFk3dyVRQB"
      },
      "source": [
        "RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbyGVlsw7hw6"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "\n",
        "# Define el espacio de búsqueda de los hiperparámetros\n",
        "param_distributions = {\n",
        "    'n_estimators': [5,10,15,20],\n",
        "    'max_depth': [3,5,7,9],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Crea el modelo a optimizar\n",
        "model = RandomForestRegressor()\n",
        "\n",
        "\n",
        "# Realiza la búsqueda de hiperparámetros con k-fold cross-validation\n",
        "search = GridSearchCV(model, param_grid=param_distributions, scoring='neg_mean_squared_error')\n",
        "\n",
        "search.fit(X_train_pca, y_train_norm)\n",
        "\n",
        "# Obtiene el modelo con los mejores hiperparámetros\n",
        "best_model = search.best_estimator_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjMqld9OdIvn"
      },
      "outputs": [],
      "source": [
        "# Mostramos los hiperparámetros del mejor modelo\n",
        "print(\"Hiperparámetros del mejor modelo:\")\n",
        "print(search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcQzeOvL7x9C"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Entrenar el modelo con todos los datos de entrenamiento\n",
        "best_model.fit(X_train_pca, y_train_norm)\n",
        "\n",
        "# Realizar predicciones con el modelo\n",
        "y_pred_train = best_model.predict(X_train_pca)\n",
        "y_pred_test = best_model.predict(X_test_pca)\n",
        "\n",
        "# Calcular el error cuadrático medio para los datos de entrenamiento y prueba\n",
        "mse_train = mean_squared_error(y_train_norm, y_pred_train)\n",
        "mse_test = mean_squared_error(y_test_norm, y_pred_test)\n",
        "\n",
        "print(\"MSE en datos de entrenamiento: \", mse_train)\n",
        "print(\"MSE en datos de prueba: \", mse_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNZw0ENm7m5u",
        "outputId": "bf45a2cd-5a1b-43d3-d3c8-ddd56fbeb641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE en datos de entrenamiento desnormalizado:  0.18127183276838701\n",
            "MSE en datos de prueba desnormalizado:  1.5623188704068616\n"
          ]
        }
      ],
      "source": [
        "y_pred_train_desnormalizado = y_scaler_train.inverse_transform(y_pred_train.reshape(-1,1))\n",
        "y_pred_test_desnormalizado = y_scaler_train.inverse_transform(y_pred_test.reshape(-1,1))\n",
        "\n",
        "mse_train_desnormalizado = mean_squared_error(y_train, y_pred_train_desnormalizado)\n",
        "mse_test_desnormalizado = mean_squared_error(y_test, y_pred_test_desnormalizado)\n",
        "\n",
        "print(\"MSE en datos de entrenamiento desnormalizado: \", mse_train_desnormalizado)\n",
        "print(\"MSE en datos de prueba desnormalizado: \", mse_test_desnormalizado)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCAGeKDb8CvL"
      },
      "outputs": [],
      "source": [
        "x=np.arange(0,len(dataFile['Output']))\n",
        "#Output\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "actual = np.append(y_train, y_test)\n",
        "predictions = np.append(y_pred_train_desnormalizado, y_pred_test_desnormalizado)\n",
        "plt.figure()\n",
        "plt.plot(x, dataFile['Output'] , label='real')\n",
        "plt.plot(x,predictions, label='prediccion')\n",
        "plt.axvline(x=len(y_train), color='red', linestyle='--')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtaAMnfYzLJp"
      },
      "outputs": [],
      "source": [
        "x=np.arange(len(y_train),len(dataFile['Output']))\n",
        "#Output\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "plt.figure()\n",
        "plt.plot(x, dataFile['Output'][len(y_train):] , label='real')\n",
        "plt.plot(x,y_pred_test_desnormalizado, label='prediccion')\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wt8K2Usj2kXj"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "\n",
        "# Define el espacio de búsqueda de los hiperparámetros\n",
        "param_distributions = {\n",
        "    'n_estimators': [5,10,15],\n",
        "    'max_depth': [3,5],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Crea el modelo a optimizar\n",
        "model = RandomForestRegressor()\n",
        "\n",
        "# Realiza la búsqueda de hiperparámetros con k-fold cross-validation\n",
        "search = GridSearchCV(model, param_grid=param_distributions, scoring='neg_mean_squared_error')\n",
        "search.fit(X_train_pca, y_train_norm)\n",
        "\n",
        "# Obtiene el modelo con los mejores hiperparámetros\n",
        "best_model = search.best_estimator_\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZrQt4bL2_eU"
      },
      "outputs": [],
      "source": [
        "# Mostramos los hiperparámetros del mejor modelo\n",
        "print(\"Hiperparámetros del mejor modelo:\")\n",
        "print(search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_aIFxXr37vX"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Entrenar el modelo con todos los datos de entrenamiento\n",
        "best_model.fit(X_train_pca, y_train_norm)\n",
        "\n",
        "# Realizar predicciones con el modelo\n",
        "y_pred_train = best_model.predict(X_train_pca)\n",
        "y_pred_test = best_model.predict(X_test_pca)\n",
        "\n",
        "# Calcular el error cuadrático medio para los datos de entrenamiento y prueba\n",
        "mse_train = mean_squared_error(y_train_norm, y_pred_train)\n",
        "mse_test = mean_squared_error(y_test_norm, y_pred_test)\n",
        "\n",
        "print(\"MSE en datos de entrenamiento: \", mse_train)\n",
        "print(\"MSE en datos de prueba: \", mse_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSnmDIT-3Cqq"
      },
      "outputs": [],
      "source": [
        "y_pred_train_desnormalizado = y_scaler_train.inverse_transform(y_pred_train.reshape(-1,1))\n",
        "y_pred_test_desnormalizado = y_scaler_train.inverse_transform(y_pred_test.reshape(-1,1))\n",
        "\n",
        "mse_train_desnormalizado = mean_squared_error(y_train, y_pred_train_desnormalizado)\n",
        "mse_test_desnormalizado = mean_squared_error(y_test, y_pred_test_desnormalizado)\n",
        "\n",
        "print(\"MSE en datos de entrenamiento desnormalizado: \", mse_train_desnormalizado)\n",
        "print(\"MSE en datos de prueba desnormalizado: \", mse_test_desnormalizado)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gba1eA8n4PZd"
      },
      "outputs": [],
      "source": [
        "x=np.arange(0,len(dataFile['Output']))\n",
        "#Output\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "actual = np.append(y_train, y_test)\n",
        "predictions = np.append(y_pred_train_desnormalizado, y_pred_test_desnormalizado)\n",
        "plt.figure()\n",
        "plt.plot(x, dataFile['Output'] , label='real')\n",
        "plt.plot(x,predictions, label='prediccion')\n",
        "plt.axvline(x=len(y_train), color='red', linestyle='--')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv-DdjWW4P50"
      },
      "outputs": [],
      "source": [
        "x=np.arange(len(y_train),len(dataFile['Output']))\n",
        "#Output\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "plt.figure()\n",
        "plt.plot(x, dataFile['Output'][len(y_train):] , label='real')\n",
        "plt.plot(x,y_pred_test_desnormalizado, label='prediccion')\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQlue3aniSpl"
      },
      "source": [
        "SVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYC5qd-aiTXQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Define el espacio de búsqueda de los hiperparámetros\n",
        "param_distributions = {\n",
        "    'C': [0.1,1,5,10],\n",
        "    'epsilon': [0.1,1,5,10],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "}\n",
        "\n",
        "# Crea el modelo a optimizar\n",
        "model = SVR()\n",
        "\n",
        "# Realiza la búsqueda de hiperparámetros con k-fold cross-validation\n",
        "search =  GridSearchCV(model,param_grid=param_distributions,\n",
        "                             scoring='neg_mean_squared_error')\n",
        "search.fit(X_train_pca, y_train_norm)\n",
        "\n",
        "# Obtiene el modelo con los mejores hiperparámetros\n",
        "best_model = search.best_estimator_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM-puhXnia-6"
      },
      "outputs": [],
      "source": [
        "# Mostramos los hiperparámetros del mejor modelo\n",
        "print(\"Hiperparámetros del mejor modelo:\")\n",
        "print(search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00p1_C5RieNV"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Entrenar el modelo con todos los datos de entrenamiento\n",
        "best_model.fit(X_train_pca, y_train_norm)\n",
        "\n",
        "# Realizar predicciones con el modelo\n",
        "y_pred_train = best_model.predict(X_train_pca)\n",
        "y_pred_test = best_model.predict(X_test_pca)\n",
        "\n",
        "# Calcular el error cuadrático medio para los datos de entrenamiento y prueba\n",
        "mse_train = mean_squared_error(y_train_norm, y_pred_train)\n",
        "mse_test = mean_squared_error(y_test_norm, y_pred_test)\n",
        "\n",
        "print(\"MSE en datos de entrenamiento: \", mse_train)\n",
        "print(\"MSE en datos de prueba: \", mse_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MjlPMgwign2"
      },
      "outputs": [],
      "source": [
        "y_pred_train_desnormalizado = y_scaler_train.inverse_transform(y_pred_train.reshape(-1,1))\n",
        "y_pred_test_desnormalizado = y_scaler_train.inverse_transform(y_pred_test.reshape(-1,1))\n",
        "\n",
        "mse_train_desnormalizado = mean_squared_error(y_train, y_pred_train_desnormalizado)\n",
        "mse_test_desnormalizado = mean_squared_error(y_test, y_pred_test_desnormalizado)\n",
        "\n",
        "print(\"MSE en datos de entrenamiento desnormalizado: \", mse_train_desnormalizado)\n",
        "print(\"MSE en datos de prueba desnormalizado: \", mse_test_desnormalizado)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkN2I_dtiilK"
      },
      "outputs": [],
      "source": [
        "x=np.arange(0,len(dataFile['Output']))\n",
        "#Output\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "actual = np.append(y_train, y_test)\n",
        "predictions = np.append(y_pred_train_desnormalizado, y_pred_test_desnormalizado)\n",
        "plt.figure()\n",
        "plt.plot(x, dataFile['Output'] , label='real')\n",
        "plt.plot(x,predictions, label='prediccion')\n",
        "plt.axvline(x=len(y_train), color='red', linestyle='--')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSJNlSmCNWZi"
      },
      "outputs": [],
      "source": [
        "x=np.arange(len(y_train),len(dataFile['Output']))\n",
        "#Output\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "plt.figure()\n",
        "plt.plot(x, dataFile['Output'][len(y_train):] , label='real')\n",
        "plt.plot(x,y_pred_test_desnormalizado, label='prediccion')\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X1vTwW3If_B"
      },
      "source": [
        "PLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oz3gjCy7Ig4H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = PLSRegression()\n",
        "\n",
        "param_distributions = {\n",
        "  'n_components': np.arange(1, X_train_norm.shape[1]+1)\n",
        "}\n",
        "# Realiza la búsqueda de hiperparámetros con k-fold cross-validation\n",
        "search =  GridSearchCV(model,param_grid=param_distributions,\n",
        "                             scoring='neg_mean_squared_error')\n",
        "search.fit(X_train_norm, y_train_norm)\n",
        "\n",
        "# Obtiene el modelo con los mejores hiperparámetros\n",
        "best_model = search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezTAxW6mkVHb"
      },
      "outputs": [],
      "source": [
        "# Mostramos los hiperparámetros del mejor modelo\n",
        "print(\"Hiperparámetros del mejor modelo:\")\n",
        "print(search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWzW-Kb8oXb0"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Entrenar el modelo con todos los datos de entrenamiento\n",
        "best_model.fit(X_train_norm, y_train_norm)\n",
        "\n",
        "# Realizar predicciones con el modelo\n",
        "y_pred_train = best_model.predict(X_train_norm)\n",
        "y_pred_test = best_model.predict(X_test_norm)\n",
        "\n",
        "# Calcular el error cuadrático medio para los datos de entrenamiento y prueba\n",
        "mse_train = mean_squared_error(y_train_norm, y_pred_train)\n",
        "mse_test = mean_squared_error(y_test_norm, y_pred_test)\n",
        "\n",
        "print(\"MSE en datos de entrenamiento: \", mse_train)\n",
        "print(\"MSE en datos de prueba: \", mse_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKQKupxLnC1i",
        "outputId": "1ca88206-81f4-4b3e-a172-7af1e5bc9c06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE en datos de entrenamiento desnormalizado:  0.11173802074724055\n",
            "MSE en datos de prueba desnormalizado:  0.7178686460372072\n"
          ]
        }
      ],
      "source": [
        "\n",
        "y_pred_train_desnormalizado = y_scaler_train.inverse_transform(y_pred_train.reshape(-1,1))\n",
        "y_pred_test_desnormalizado = y_scaler_train.inverse_transform(y_pred_test.reshape(-1,1))\n",
        "\n",
        "mse_train_desnormalizado = mean_squared_error(y_train, y_pred_train_desnormalizado)\n",
        "mse_test_desnormalizado = mean_squared_error(y_test, y_pred_test_desnormalizado)\n",
        "\n",
        "print(\"MSE en datos de entrenamiento desnormalizado: \", mse_train_desnormalizado)\n",
        "print(\"MSE en datos de prueba desnormalizado: \", mse_test_desnormalizado)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53T6Lm36ozB5"
      },
      "outputs": [],
      "source": [
        "x=np.arange(0,len(dataFile['Output']))\n",
        "#Output\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "actual = np.append(y_train, y_test)\n",
        "predictions = np.append(y_pred_train_desnormalizado, y_pred_test_desnormalizado)\n",
        "plt.figure()\n",
        "plt.plot(x, dataFile['Output'] , label='real')\n",
        "plt.plot(x,predictions, label='prediccion')\n",
        "plt.axvline(x=len(y_train), color='red', linestyle='--')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1orvW8PlmFc"
      },
      "outputs": [],
      "source": [
        "x=np.arange(len(y_train),len(dataFile['Output']))\n",
        "#Output\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "plt.figure()\n",
        "plt.plot(x, dataFile['Output'][len(y_train):] , label='real')\n",
        "plt.plot(x,y_pred_test_desnormalizado, label='prediccion')\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ1T960nmaIf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = PLSRegression()\n",
        "\n",
        "param_distributions = {\n",
        "  'n_components': np.arange(1, X_train_pca.shape[1]+1)\n",
        "}\n",
        "# Realiza la búsqueda de hiperparámetros con k-fold cross-validation\n",
        "search =  GridSearchCV(model,param_grid=param_distributions,\n",
        "                             scoring='neg_mean_squared_error')\n",
        "search.fit(X_train_norm, y_train_norm)\n",
        "\n",
        "# Obtiene el modelo con los mejores hiperparámetros\n",
        "best_model = search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQA26z0SmsdY"
      },
      "outputs": [],
      "source": [
        "# Mostramos los hiperparámetros del mejor modelo\n",
        "print(\"Hiperparámetros del mejor modelo:\")\n",
        "print(search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2ZSrC2Kmx0J"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Entrenar el modelo con todos los datos de entrenamiento\n",
        "best_model.fit(X_train_norm, y_train_norm)\n",
        "\n",
        "# Realizar predicciones con el modelo\n",
        "y_pred_train = best_model.predict(X_train_norm)\n",
        "y_pred_test = best_model.predict(X_test_norm)\n",
        "\n",
        "# Calcular el error cuadrático medio para los datos de entrenamiento y prueba\n",
        "mse_train = mean_squared_error(y_train_norm, y_pred_train)\n",
        "mse_test = mean_squared_error(y_test_norm, y_pred_test)\n",
        "\n",
        "print(\"MSE en datos de entrenamiento: \", mse_train)\n",
        "print(\"MSE en datos de prueba: \", mse_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaH1gDtnnwfd"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_pred_train_desnormalizado = y_scaler_train.inverse_transform(y_pred_train.reshape(-1,1))\n",
        "y_pred_test_desnormalizado = y_scaler_train.inverse_transform(y_pred_test.reshape(-1,1))\n",
        "\n",
        "mse_train_desnormalizado = mean_squared_error(y_train, y_pred_train_desnormalizado)\n",
        "mse_test_desnormalizado = mean_squared_error(y_test, y_pred_test_desnormalizado)\n",
        "\n",
        "print(\"MSE en datos de entrenamiento desnormalizado: \", mse_train_desnormalizado)\n",
        "print(\"MSE en datos de prueba desnormalizado: \", mse_test_desnormalizado)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.arange(0,len(dataFile['Output']))\n",
        "#Output\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "actual = np.append(y_train, y_test)\n",
        "predictions = np.append(y_pred_train_desnormalizado, y_pred_test_desnormalizado)\n",
        "plt.figure()\n",
        "plt.plot(x, dataFile['Output'] , label='real')\n",
        "plt.plot(x,predictions, label='prediccion')\n",
        "plt.axvline(x=len(y_train), color='red', linestyle='--')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "pVNjB4SQ2omi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.arange(len(y_train),len(dataFile['Output']))\n",
        "#Output\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "plt.figure()\n",
        "plt.plot(x, dataFile['Output'][len(y_train):] , label='real')\n",
        "plt.plot(x,y_pred_test_desnormalizado, label='prediccion')\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "074UAVFh2qbH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjTTYjbV39A7K0o8oEjwoO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}